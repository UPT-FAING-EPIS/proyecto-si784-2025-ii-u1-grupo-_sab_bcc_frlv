# ğŸ”’ Anti-Keylogger ML Pipeline

Un pipeline completo de Machine Learning para la detecciÃ³n de keyloggers usando tÃ©cnicas avanzadas de ciencia de datos.

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n](#descripciÃ³n)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [InstalaciÃ³n](#instalaciÃ³n)
- [Uso RÃ¡pido](#uso-rÃ¡pido)
- [Pipeline Detallado](#pipeline-detallado)
- [ConfiguraciÃ³n](#configuraciÃ³n)
- [API REST](#api-rest)
- [ContribuciÃ³n](#contribuciÃ³n)

## ğŸ¯ DescripciÃ³n

Este proyecto implementa un pipeline completo de Machine Learning para detectar keyloggers usando:

- **Preprocesamiento avanzado**: Limpieza de datos, manejo de valores faltantes, detecciÃ³n de outliers
- **MÃºltiples algoritmos**: Random Forest, XGBoost, LightGBM con hyperparameter tuning
- **EvaluaciÃ³n comprehensiva**: MÃ©tricas detalladas, anÃ¡lisis de robustez, detecciÃ³n de drift
- **Deployment automÃ¡tico**: API REST, procesamiento batch, inferencia en tiempo real
- **Monitoreo**: Tracking de rendimiento, anÃ¡lisis de confianza de predicciones

## ğŸ“ Estructura del Proyecto

```
Python_ML/
â”œâ”€â”€ ğŸ“Š data/
â”‚   â”œâ”€â”€ raw/              # Datos originales (CSV)
â”‚   â”œâ”€â”€ processed/        # Datos procesados (Parquet, Pickle)
â”‚   â”œâ”€â”€ external/         # Datos externos
â”‚   â””â”€â”€ features/         # Features engineered
â”œâ”€â”€ ğŸ““ notebooks/
â”‚   â””â”€â”€ 01_exploratory_data_analysis.ipynb
â”œâ”€â”€ ğŸ§ª data_science/
â”‚   â””â”€â”€ data_preprocessing.py
â”œâ”€â”€ ğŸ¤– ml_pipeline/
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ train_model.py
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â””â”€â”€ evaluate_model.py
â”‚   â””â”€â”€ deployment/
â”‚       â””â”€â”€ predict_model.py
â”œâ”€â”€ ğŸ’¾ models/
â”‚   â”œâ”€â”€ development/      # Modelos en desarrollo
â”‚   â”œâ”€â”€ production/       # Modelos en producciÃ³n
â”‚   â”œâ”€â”€ evaluation/       # Reportes de evaluaciÃ³n
â”‚   â””â”€â”€ predictions/      # Resultados de predicciones
â”œâ”€â”€ ğŸ“ logs/              # Logs del pipeline
â”œâ”€â”€ ğŸ”§ config.toml        # ConfiguraciÃ³n
â”œâ”€â”€ ğŸš€ run_pipeline.py    # Orquestador principal
â””â”€â”€ ğŸ“„ requirements.txt   # Dependencias
```

## ğŸ› ï¸ InstalaciÃ³n

### 1. Clonar el repositorio
```bash
git clone https://github.com/tu-usuario/Python_ML.git
cd Python_ML
```

### 2. Crear entorno virtual
```bash
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac
```

### 3. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 4. Configurar datos
Coloca tus archivos CSV en la carpeta `data/raw/`:
```bash
data/raw/
â”œâ”€â”€ keylogger_dataset_small.csv
â””â”€â”€ keylogger_dataset_large.csv
```

## ğŸš€ Uso RÃ¡pido

### Pipeline Completo (Recomendado)
```bash
python run_pipeline.py --stage all
```

### Etapas Individuales
```bash
# Solo preprocesamiento
python run_pipeline.py --stage preprocess

# Solo entrenamiento
python run_pipeline.py --stage train

# Solo evaluaciÃ³n
python run_pipeline.py --stage evaluate

# Solo predicciones
python run_pipeline.py --stage predict
```

## ğŸ”¬ Pipeline Detallado

### 1. ğŸ“Š Preprocesamiento de Datos

**Archivo**: `data_science/data_preprocessing.py`

**CaracterÃ­sticas**:
- âœ… AnÃ¡lisis de calidad de datos automÃ¡tico
- âœ… Limpieza de valores faltantes y outliers
- âœ… Encoding de variables categÃ³ricas
- âœ… NormalizaciÃ³n y escalado
- âœ… Export a mÃºltiples formatos (Parquet, Pickle, HDF5)

**Uso**:
```python
from data_science.data_preprocessing import DataPreprocessor

preprocessor = DataPreprocessor()
df = preprocessor.load_data("data/raw/dataset.csv")
df_clean = preprocessor.clean_data(df)
preprocessor.export_processed_data(df_clean, "clean_dataset")
```

### 2. ğŸ¤– Entrenamiento de Modelos

**Archivo**: `ml_pipeline/training/train_model.py`

**CaracterÃ­sticas**:
- âœ… MÃºltiples algoritmos (Random Forest, XGBoost, LightGBM)
- âœ… Hyperparameter tuning con Grid Search
- âœ… Cross-validation estratificada
- âœ… Export a PKL y ONNX
- âœ… Feature importance analysis

**Uso**:
```python
from ml_pipeline.training.train_model import AdvancedModelTrainer

trainer = AdvancedModelTrainer()
summary = trainer.full_training_pipeline(
    data_path="data/processed/clean_dataset.parquet",
    target_column="class"
)
```

### 3. ğŸ“ˆ EvaluaciÃ³n de Modelos

**Archivo**: `ml_pipeline/evaluation/evaluate_model.py`

**CaracterÃ­sticas**:
- âœ… MÃ©tricas comprehensivas (Accuracy, F1, ROC-AUC, etc.)
- âœ… AnÃ¡lisis de matriz de confusiÃ³n
- âœ… DetecciÃ³n de data drift
- âœ… AnÃ¡lisis de confianza de predicciones
- âœ… ComparaciÃ³n automÃ¡tica de modelos

**Uso**:
```python
from ml_pipeline.evaluation.evaluate_model import ModelEvaluator

evaluator = ModelEvaluator()
result = evaluator.evaluate_model_comprehensive(
    model_path="models/development/best_model.pkl",
    test_data_path="data/processed/test_data.parquet",
    target_column="class"
)
```

### 4. ğŸ¯ Deployment y Predicciones

**Archivo**: `ml_pipeline/deployment/predict_model.py`

**CaracterÃ­sticas**:
- âœ… PredicciÃ³n individual y batch
- âœ… API REST con FastAPI
- âœ… Procesamiento de archivos grandes por chunks
- âœ… ValidaciÃ³n de entrada automÃ¡tica
- âœ… Monitoreo de rendimiento

**Uso**:
```python
from ml_pipeline.deployment.predict_model import ModelPredictor

predictor = ModelPredictor("models/production/best_model.pkl")
result = predictor.predict_single(features_array)
```

## âš™ï¸ ConfiguraciÃ³n

El archivo `config.toml` contiene toda la configuraciÃ³n del pipeline:

```toml
[pipeline]
project_name = "Anti-Keylogger ML Pipeline"
version = "1.0.0"

[data]
missing_threshold = 0.95
outlier_method = "iqr"
preferred_format = "parquet"

[models]
algorithms = ["random_forest", "xgboost", "lightgbm"]
test_size = 0.2
cv_folds = 5

[evaluation]
min_accuracy = 0.85
min_f1_score = 0.80
```

## ğŸŒ API REST

### Iniciar el servidor
```python
from ml_pipeline.deployment.predict_model import ModelPredictor, ModelAPI

predictor = ModelPredictor("models/production/best_model.pkl")
api = ModelAPI(predictor)
api.run(host="0.0.0.0", port=8000)
```

### Endpoints disponibles

| Endpoint | MÃ©todo | DescripciÃ³n |
|----------|--------|-------------|
| `/` | GET | Estado de la API |
| `/health` | GET | Health check |
| `/predict` | POST | PredicciÃ³n individual |
| `/predict/batch` | POST | PredicciÃ³n batch |
| `/model/info` | GET | InformaciÃ³n del modelo |
| `/stats` | GET | EstadÃ­sticas de uso |

### Ejemplo de uso
```bash
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{"features": [1.0, 2.0, 3.0, ...]}'
```

## ğŸ“Š Jupyter Notebooks

### AnÃ¡lisis Exploratorio de Datos
El notebook `notebooks/01_exploratory_data_analysis.ipynb` incluye:

- ğŸ“ˆ EstadÃ­sticas descriptivas
- ğŸ“Š Visualizaciones de distribuciones
- ğŸ” AnÃ¡lisis de correlaciones
- ğŸ§¹ IdentificaciÃ³n de problemas de calidad
- ğŸ¯ Insights para feature engineering

## ğŸ“‹ Ejemplos de Uso

### Ejemplo 1: Pipeline bÃ¡sico
```python
# Ejecutar todo el pipeline
python run_pipeline.py --stage all

# Ver resultados
ls models/development/  # Modelos entrenados
ls models/evaluation/   # Reportes de evaluaciÃ³n
ls models/predictions/  # Predicciones
```

### Ejemplo 2: Entrenamiento personalizado
```python
from ml_pipeline.training.train_model import AdvancedModelTrainer

trainer = AdvancedModelTrainer()
trainer.create_model_configurations()  # Ver configuraciones
summary = trainer.full_training_pipeline(
    data_path="mi_dataset.parquet",
    target_column="mi_target"
)
print(f"Mejor modelo: {summary['best_model']}")
```

### Ejemplo 3: Predicciones en producciÃ³n
```python
from ml_pipeline.deployment.predict_model import ModelPredictor, BatchProcessor

# Cargar modelo
predictor = ModelPredictor("models/production/modelo_final.pkl")

# PredicciÃ³n individual
features = np.array([...])  # Tus features
result = predictor.predict_single(features)
print(f"PredicciÃ³n: {result['prediction_label']}")
print(f"Confianza: {result['confidence']:.2%}")

# Procesamiento batch
batch_processor = BatchProcessor(predictor)
batch_processor.process_csv_file("nuevos_datos.csv")
```

## ğŸ”§ Troubleshooting

### Problema: Error de importaciÃ³n
```bash
# SoluciÃ³n: Agregar al PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:${PWD}"
```

### Problema: Memoria insuficiente
```python
# Usar chunks mÃ¡s pequeÃ±os en el config.toml
[deployment]
batch_chunk_size = 5000
```

### Problema: Modelos no encontrados
```bash
# Verificar estructura
python run_pipeline.py --stage train
ls models/development/
```

## ğŸ“ˆ MÃ©tricas y Monitoreo

El pipeline genera automÃ¡ticamente:

- ğŸ“Š **Reportes de rendimiento**: Accuracy, F1, ROC-AUC
- ğŸ¯ **AnÃ¡lisis de confianza**: DistribuciÃ³n de probabilidades
- ğŸ“‰ **DetecciÃ³n de drift**: Cambios en distribuciÃ³n de datos
- â±ï¸ **MÃ©tricas de latencia**: Tiempo de predicciÃ³n
- ğŸ’¾ **Uso de recursos**: CPU y memoria

## ğŸ¤ ContribuciÃ³n

1. Fork del proyecto
2. Crear branch de feature (`git checkout -b feature/AmazingFeature`)
3. Commit cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push al branch (`git push origin feature/AmazingFeature`)
5. Abrir Pull Request

## ğŸ“œ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

## ğŸ‘¥ Autores

- **Data Science Team** - *Trabajo inicial* - [TuPerfil](https://github.com/tu-usuario)

## ğŸ™ Agradecimientos

- Comunidad de Machine Learning
- Contribuidores de scikit-learn, XGBoost, LightGBM
- Equipo de FastAPI y Jupyter

---

â­ **Â¡Si este proyecto te ayuda, dale una estrella!** â­